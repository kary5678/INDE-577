{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting\n",
    "\n",
    "This notebook implements boosting, which is an ensemble method that combines several weak models to make a final prediction. Specifically, each model will attempt to correct the mistakes made by the previous models.\n",
    "\n",
    "Unlike bagging, boosting does not involve sampling the data randomly or training models independently. Instead, boosting adjusts the weights of misclassified data points to focus on the instances that are difficult to predict. Furthermore, boosting is primarily used to reduce model bias. This is thanks to the sequential training of weak models allowing the model to gradually refine its ability to capture complex patterns in the data.\n",
    "\n",
    "The scikit-learn library has two boosting methods that I will be exploring: AdaBoost and Gradient Boosting.\n",
    "\n",
    "---\n",
    "\n",
    "First, load the relevant libraries needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Import a nice function for plotting decision boundaries\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "# Set the Seaborn theme\n",
    "sns.set_theme()\n",
    "\n",
    "# Import functions to help with training/testing endeavors and evaluate performance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Import functions to perform boosting, with relevant models\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "The model will be trained using the [Hawks](https://github.com/kary5678/INDE-577/blob/main/Data/hawks.csv) dataset. This dataset contains observations for three species of hawks, and attributes such as age, sex, wing length, body weight, tail length, etc. \n",
    "\n",
    "The code block below reads the dataset into a pandas DataFrame object, subsets the DataFrame to the relevant variables, and drops any rows where there are missing values for these relevant variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "      <th>Wing</th>\n",
       "      <th>Tail</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Culmen</th>\n",
       "      <th>Hallux</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT</td>\n",
       "      <td>385.0</td>\n",
       "      <td>219</td>\n",
       "      <td>920.0</td>\n",
       "      <td>25.7</td>\n",
       "      <td>30.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT</td>\n",
       "      <td>381.0</td>\n",
       "      <td>235</td>\n",
       "      <td>990.0</td>\n",
       "      <td>26.7</td>\n",
       "      <td>31.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CH</td>\n",
       "      <td>265.0</td>\n",
       "      <td>220</td>\n",
       "      <td>470.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>23.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SS</td>\n",
       "      <td>205.0</td>\n",
       "      <td>157</td>\n",
       "      <td>170.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>14.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RT</td>\n",
       "      <td>412.0</td>\n",
       "      <td>230</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>32.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>RT</td>\n",
       "      <td>380.0</td>\n",
       "      <td>224</td>\n",
       "      <td>1525.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>SS</td>\n",
       "      <td>190.0</td>\n",
       "      <td>150</td>\n",
       "      <td>175.0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>15.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>RT</td>\n",
       "      <td>360.0</td>\n",
       "      <td>211</td>\n",
       "      <td>790.0</td>\n",
       "      <td>21.9</td>\n",
       "      <td>27.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>RT</td>\n",
       "      <td>369.0</td>\n",
       "      <td>207</td>\n",
       "      <td>860.0</td>\n",
       "      <td>25.2</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>RT</td>\n",
       "      <td>199.0</td>\n",
       "      <td>222</td>\n",
       "      <td>1290.0</td>\n",
       "      <td>28.7</td>\n",
       "      <td>32.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Species   Wing  Tail  Weight  Culmen  Hallux\n",
       "0        RT  385.0   219   920.0    25.7    30.1\n",
       "2        RT  381.0   235   990.0    26.7    31.3\n",
       "3        CH  265.0   220   470.0    18.7    23.5\n",
       "4        SS  205.0   157   170.0    12.5    14.3\n",
       "5        RT  412.0   230  1090.0    28.5    32.2\n",
       "..      ...    ...   ...     ...     ...     ...\n",
       "903      RT  380.0   224  1525.0    26.0    27.6\n",
       "904      SS  190.0   150   175.0    12.7    15.4\n",
       "905      RT  360.0   211   790.0    21.9    27.6\n",
       "906      RT  369.0   207   860.0    25.2    28.0\n",
       "907      RT  199.0   222  1290.0    28.7    32.1\n",
       "\n",
       "[891 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data and subset it to the relevant columns/observations\n",
    "hawks = pd.read_csv(\"../../../Data/hawks.csv\")\n",
    "hawks = hawks[[\"Species\", \"Wing\", \"Tail\", \"Weight\", \"Culmen\", \"Hallux\"]].dropna(axis=0)\n",
    "hawks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1A. Logistic Regression\n",
    "\n",
    "Logistic regression is often used as a weak learner in boosting because it is computationally efficient and has low complexity."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1B. Decision Stumps\n",
    "\n",
    "Decision stumps, which are decision trees with a single split, are often used as the weak learners in boosting. This is because decision stumps have low complexity and can capture simple patterns in the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1C. Decision Trees\n",
    " \n",
    "Decision trees are the most commonly used base models in boosting due to their simplicity and ability to capture complex interactions between features."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, neural networks can also be used as base models in boosting. However, due to their high complexity, neural networks are often used in combination with other weaker models to create a diverse set of base models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
